# Dealing with paginated responses

When you request a list of items for a server, the server may send you an incomplete list. This is done to protect the servers from overexerting.

Imagine if you're googling and Google returns all 1,000,000 results to you. Would you be overwhelmed? Do you need so many resources? Probably not. Maybe you need the first few. If you only need the first few, the server doesn't have to do the work to find the next 999,990 items.

That makes sense, doesn't it?

But let's say you want to fetch every resource. How do you work through the paginated responses?

That's what we're going to cover this lesson. It's going to be a bit long winded because this is my first time. I'm sure it'll become better as I go along.

There are two ways to do it:

1. Increase the number of responses per page
2. Perform multiple requests until you get all resources

I'm worried that Github won't allow unauthenticated responses once it uses Graph APIs. I want to work around this issue as much as possible, but I ack that this is not the time to think about it. I can look at this during my breaks or after work, or during another session. Not now, when I am trying to create another material. Put it aside for now. Gonna come back to it later.

## Increase the number of responses per page

Some APIs let you increase the number of responses you get with every request. Github, for example, lets you fetch up to 100 resources per page.

[Github page link] + Image

Different API gives you different number of responses. You need to read up on the API documentations to get a sense.
Some APIs, like Pokedex, use `limit` instead of `per_page`.

## Perform multiple requests

APIs that limit the number of responses often tell you that there's a next page. This information can usually be found in the headers or body.

Github gives you the information in the headers.

And some other example gives you information in the body?

Well' I need to work on some demo to be able to fetch this out, so I kinda have to work through a demo right now, or I won't be able to contitue.

But the general idea is:

1. Get the header
2. Check for Link
3. Get the page to parse for
4. Create a Promise.all
5. Wait for all promises to resolve
6. Do your thing

The things I need to test for are:

1. How to get headers in XHR and Fetch
2. How to get the Link header + body content in both methods
3. How to use the Link header to fetch resources

Then if there is no link. I need to work with recursion. Fetch until there are no more resources, or the number of resources don't match the limit you set.

This will mean explaining recursion. Actually I can write the thing first, then explain that this process is called recursion.

But well, have to test it out first too!

Gonna set per_page to 5. This will fetch more stuff.

Response headers => Chrome/Firefox devtools. Click on Network tab. Click on the resource you requested for. You will be able to see information, including headers, preview, response, and timing, query parameters (if any)

## Avoid fetching all resources.

What if there are 10,000 items? It's not worth the effort to parse through all 10,000 items if you only need one of them. You can create pagination too. Like Google. Maybe create one... Hmmm. Gotta think of it and check whether Dota supports paging. Otherwise, let's do a Pokedex paging.

We can also do a list-all for Pokedex, which can be fun. Then I'll talk about how you can do pagination with JavaScript ğŸ¤“

But anyway, you'll need the link header information.  Can organize later. Hm. Also need to think about where to teach reduce. This is becoming more of a challenge lol.

## Parsing the Link header

String. Need to figure out what we need. Here is where Regular Expressions and other String methods come in handy. We are not going to go into details about regular expressions, but you can find out more on regexone.com. They have an excellent tutorial about regex.

We first need to decide what we want to search for.

Regular Expressions is another way la. But we can use some string methods too.

Some useful string methods are:

1. split
2. replace

```js
const parseLinkHeader = (string) => {
  const arr = string.split(',')
  return arr.reduce((o, str) => {
    const parts = str.split(';')
    const link = parts[0].replace('<', '').replace('>', '').trim()
    const rel = parts[1].replace('rel="', '').replace('"', '').trim()
    return Object.assign({}, o, {
      [rel]: link
    })
  }, {})
}

```
